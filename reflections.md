Reflections
===========

<!--
This file generated by the build script at ./Build.hs from the files in
./reflections.  If you want to edit this, edit those instead!
-->

*[2016][]* / *[2017][]* / *[2018][]* / *[2019][]* / *2020*

[2016]: https://github.com/mstksg/advent-of-code-2016/blob/master/reflections.md
[2017]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md
[2018]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md
[2019]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md

[Available as an RSS Feed][rss]

[rss]: http://feeds.feedburner.com/jle-advent-of-code-2020

Table of Contents
-----------------

* [Day 1](#day-1)

Day 1
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day01.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d01p]* / *[Code][d01g]* / *[Rendered][d01h]*

[d01p]: https://adventofcode.com/2020/day/1
[d01g]: https://github.com/mstksg/advent-of-code-2020/blob/master/src/AOC/Challenge/Day01.hs
[d01h]: https://mstksg.github.io/advent-of-code-2020/src/AOC.Challenge.Day01.html

Day 1 is usually a fun one to do in Haskell! :D  Today we can do something nice
with `tails`:

```haskell
ghci> tails [1,2,3,4]
[1:[2,3,4], 2:[3,4], 3:[4], 4:[]]
```

It lets you separate out each item in a list with the list of items after it.

Part 1 then becomes, with the list monad to simulate searches:

```haskell
findPair :: [Int] -> Maybe Int
findPair xs = listToMaybe $ do
    x:ys <- tails xs
    y    <- ys
    guard (x + y == 2020)
    pure (x*y)
```

And Part 2 is not much more complicated:

```haskell
findTriple :: [Int] -> Maybe Int
findTriple xs = listToMaybe $ do
    x:ys <- tails xs
    y:zs <- tails ys
    z    <- zs
    guard (x + y + z == 2020)
    pure (x*y*z)
```

The simpler way would be to just `do x <- xs; y <- xs; z <- xs; ...`, and
either hope that you don't accidentally select a duplicate, or validate that
you didn't draw any duplicates.  But it's always fun to do selecty constrainty
searches when you have the opportunity :D


### Day 1 Benchmarks

```
>> Day 01a
benchmarking...
time                 35.01 μs   (35.00 μs .. 35.02 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 35.04 μs   (35.03 μs .. 35.05 μs)
std dev              18.87 ns   (14.79 ns .. 27.67 ns)

* parsing and formatting times excluded

>> Day 01b
benchmarking...
time                 1.771 ms   (1.767 ms .. 1.775 ms)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 1.752 ms   (1.748 ms .. 1.758 ms)
std dev              16.20 μs   (15.16 μs .. 17.06 μs)

* parsing and formatting times excluded
```

